{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generating videos of motion\n",
    "Tim Tyree<br>\n",
    "12.6.2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T23:31:18.348878Z",
     "start_time": "2020-12-13T23:31:15.572428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic calling is: Smart\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from lib.my_initialization import *\n",
    "from lib.controller.integrate_forward_dormand_prince_asynchronous import *\n",
    "from lib.controller.integrate_forward_implicit_asynchronous import *\n",
    "%autocall 1\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T23:31:19.485140Z",
     "start_time": "2020-12-13T23:31:18.350727Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['element_array_time', 'element_array_index', 'element_array_mass', 'element_array_volume', 'element_array_inverse_equilibrium_position', 'node_array_equilibrium_position', 'node_array_time', 'node_array_position', 'node_array_momentum', 'node_array_mass', 'node_array_volume']\n"
     ]
    }
   ],
   "source": [
    "#define Lamé parameters\n",
    "mu = 10.; lam = 1.; \n",
    "#define coefficient for Rayleigh damping\n",
    "gamma = 0.1#1.#1.;\n",
    "#define adaptive time stepping absolute tolerances\n",
    "salience = 1#128#32\n",
    "learning_rate = np.log(salience) #np.log(16) #np.log(2)\n",
    "lasso_fraction = 0.5#not used rn...\n",
    "v_scale = 2.\n",
    "mass_density=1.\n",
    "stepsize_init = 0.001#0.00001  #0.0001\n",
    "atol_x = 1e-05#0.0001#0.001#1e-7; \n",
    "atol_v = 1e-05#0.0001#0.001#1e-7; \n",
    "btol_x = 1e-07#0.00001#0.001#1e-10; \n",
    "btol_v = 1e-07#0.00001#0.001#1e-10; \n",
    "input_file_name = f'../data/spherical_meshes/spherical_mesh_64.stl'#path to mesh\n",
    "data_folder =  os.path.join(nb_dir,'../data/mov_csv')#where to save results\n",
    "\n",
    "\n",
    "data_fn = f\"explicit_asynch_fixed_lr_{os.path.basename(input_file_name).replace('.stl',f'_mu_{mu}_lambda_{lam}_gamma_{gamma}vscale_{v_scale}_stepsizeinit_{stepsize_init}')}_salience_{salience}_atolx_{atol_x}.csv\"\n",
    "# data_fn = f\"dormand_prince_asynch_fixed_lr_{os.path.basename(input_file_name).replace('.stl',f'_mu_{mu}_lambda_{lam}_gamma_{gamma}vscale_{v_scale}_stepsizeinit_{stepsize_init}')}_salience_{salience}_atolx_{atol_x}.csv\"\n",
    "TEXTfoo = lambda N_vertices,N_elements: f\"\"\"\n",
    "TEXT=$'an inward squish\n",
    "        Asynchronous Variational Integrator \n",
    "        Explicit Newmark Method\n",
    "        \n",
    "        Undamped Neohookean Model\n",
    "        mu {mu}  lambda {lam} gamma {gamma}\n",
    "        \n",
    "        Spherical Mesh\n",
    "        Num. Vertices {N_vertices}\n",
    "        Num. Elements {N_elements}\n",
    "'\"\"\"\n",
    "\n",
    "# data_fn = f\"avi_esynchronous_fixed_lr_a_equal_b_{os.path.basename(input_file_name).replace('.stl',f'_mu_{mu}_lambda_{lam}_gamma_{gamma}_vscale_{v_scale}_stepsizeinit_{stepsize_init}')}_salience_{salience}_atolx_{atol_x}.csv\"\n",
    "# data_fn = f\"avi_ns_fixed_lr_a_equal_b_{os.path.basename(input_file_name).replace('.stl',f'_mu_{mu}_lambda_{lam}_gamma_{gamma}vscale_{v_scale}_stepsizeinit_{stepsize_init}')}_salience_{salience}_atolx_{atol_x}.csv\"\n",
    "# data_fn = f\"dormand_prince_synch_fixed_lr_{os.path.basename(input_file_name).replace('.stl',f'_mu_{mu}_lambda_{lam}_gamma_{gamma}vscale_{v_scale}_stepsizeinit_{stepsize_init}')}_salience_{salience}_atolx_{atol_x}.csv\"\n",
    "save_folder_vid = '../vid/tmp2'\n",
    "folder_vid = '../vid'\n",
    "# data_fn_counts = data_fn.replace(\"s_\",\"s_counts_\").replace('.csv','.npz')\n",
    "data_fn_counts = data_fn.replace(\"s_\",\"s_counts_\").replace('.csv','.npy')\n",
    "os.chdir(nb_dir)\n",
    "# input_file_name = f'../data/spherical_meshes/spherical_mesh_64.stl'input_file_name = f'../data/spherical_meshes/spherical_mesh_64.stl'\n",
    "# input_file_name = f'../data/spherical_meshes/spherical_mesh_1000.stl'\n",
    "input_file_name = os.path.join(nb_dir,input_file_name)\n",
    "tme = 0.\n",
    "dict_values_system = initialize_system(input_file_name, time_initial=tme, mass_density=mass_density)\n",
    "locals().update(dict_values_system)\n",
    "N_elements = element_array_index.shape[0]\n",
    "N_vertices = node_array_position.shape[0]\n",
    "TEXT = TEXTfoo(N_vertices,N_elements)\n",
    "print(list(dict_values_system.keys()))\n",
    "\n",
    "#header to start of video\n",
    "# TEXT = '''TEXT=$'Synchronous Variational Integrator\\nDamped Neohookean Model\\n(inward squish)''''\n",
    "# TEXT = f\"\"\"\n",
    "# TEXT=$'an inward squish\n",
    "#         Synchronous Variational Integrator \n",
    "#         Explicit Newmark Method\n",
    "        \n",
    "#         Undamped Neohookean Model\n",
    "#         mu {mu}  lambda {lam} gamma {gamma}\n",
    "        \n",
    "#         Spherical Mesh\n",
    "#         Num. Vertices {N_vertices}\n",
    "#         Num. Elements {N_elements}\n",
    "# '\"\"\"\n",
    "\n",
    "#write header to file\n",
    "# print(TEXT)\n",
    "# Dormand–Prince Method\n",
    "# Explicit Newmark Method\n",
    "# Implicit Midpoint Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T07:19:52.630328Z",
     "start_time": "2020-12-13T07:19:52.607467Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicit/Implicit Synchronous/Asynchronous Variational Integrator\n",
    "\n",
    "- Mesh = solid sphere discretized by tetrahedra \n",
    "- Forces = neohookean hyperelastic material with rayleigh damping\n",
    "- Initialization = inward initial velocity by an amount proportional to the x coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T23:31:19.517587Z",
     "start_time": "2020-12-13T23:31:19.487170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_bins are [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
      " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
      " 0.001 0.001 0.001 0.001 0.001 0.001]\n"
     ]
    }
   ],
   "source": [
    "#initialize system\n",
    "tauK = element_array_time\n",
    "tau = node_array_time\n",
    "\n",
    "#get method of computing elastic forces \n",
    "zero_mat = np.zeros((4,3))\n",
    "# calc_P = get_calc_P(mu, lam)\n",
    "# compute_nodal_damping_forces  = get_compute_nodal_damping_forces(mu,lam,gamma)\n",
    "# comp_nodal_elastic_forces = get_comp_nodal_elastic_forces(mu, lam)\n",
    "\n",
    "elements = element_array_index\n",
    "vertices = node_array_position\n",
    "\n",
    "#initialize stepsizes of simulation\n",
    "element_array_stepsize = np.zeros_like(element_array_time) + stepsize_init\n",
    "element_array_count_calls_one_step = np.zeros_like(element_array_time,dtype=int)\n",
    "element_array_count_config_updates = np.zeros_like(element_array_time,dtype=int)\n",
    "momentum = node_array_momentum.copy()\n",
    "velocities = momentum.copy()\n",
    "for j in range(N_vertices):\n",
    "    velocities[j] /= node_array_mass[j]\n",
    "\n",
    "\n",
    "# #perturb momentum in the x direction and let it run overnight with a small timestep  \n",
    "velocities[:,0] = -v_scale * vertices[:,0].copy()\n",
    "\n",
    "#initialize containers of measures\n",
    "volume_lst = []\n",
    "energy_lst = []\n",
    "tme_lst    = []\n",
    "stepsize_mean_lst   = []\n",
    "stepsize_std_lst    = []\n",
    "stepsize_median_lst = []\n",
    "stepsize_count_lst = []\n",
    "frac_lb = lambda i: np.exp(learning_rate*i)  ##np.exp((i+.5)*learning_rate/10)\n",
    "learning_bins = np.array([stepsize_init*frac_lb(i) for i in np.arange(-15,15)])\n",
    "\n",
    "# learning_bins = np.array([stepsize_init*np.exp((i+.5)*learning_rate) for i in np.arange(-3,3)])\n",
    "print(f\"learning_bins are {learning_bins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T23:31:19.542172Z",
     "start_time": "2020-12-13T23:31:19.519757Z"
    }
   },
   "outputs": [],
   "source": [
    "#choose your fighter\n",
    "# integrate_system_explicit_synchronous = get_integrate_system_explicit_synchronous(mu,lam,gamma)\n",
    "integrate_system_explicit_asynchronous = get_integrate_system_explicit_asynchronous(mu,lam,gamma)\n",
    "# integrate_system_implicit_synchronous = get_integrate_system_implicit_synchronous(mu,lam,gamma,num_iter=30)\n",
    "# integrate_system_implicit_asynchronous = get_integrate_system_implicit_asynchronous(mu,lam,gamma)\n",
    "# integrate_system_dormand_prince_synchronous = get_integrate_system_dormand_prince_synchronous(mu,lam,gamma)\n",
    "# integrate_system_dormand_prince_asynchronous = get_integrate_system_dormand_prince_asynchronous(mu,lam,gamma,atol_x, atol_v, btol_x, btol_v,learning_rate, lasso_fraction)\n",
    "# mode = 'fixed_lr'#'neural_lr'\n",
    "# integrate_system_dormand_prince_asynchronous = get_integrate_system_dormand_prince_asynchronous(mu,lam,gamma,atol_x, atol_v, btol_x, btol_v,learning_rate, lasso_fraction)\n",
    "\n",
    "\n",
    "#(optional) #view the mesh\n",
    "# plot_mesh(vertices, input_file_name=input_file_name, darkmode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T23:31:19.564216Z",
     "start_time": "2020-12-13T23:31:19.543785Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_integrate_system(mode):\n",
    "#     if mode==0:\n",
    "#         return integrate_system_explicit_synchronous(tf, element_array_time, element_array_stepsize, node_array_time,element_array_index, vertices, velocities,node_array_mass, element_array_inverse_equilibrium_position)\n",
    "#     #     integrate_system_explicit_asynchronous(tf, element_array_time, element_array_stepsize, node_array_time,element_array_index, vertices, velocities, node_array_mass, element_array_inverse_equilibrium_position, atol_x, atol_v, btol_x, btol_v, learning_rate)\n",
    "#     #     integrate_system_implicit_synchronous(tf, element_array_time, element_array_stepsize, node_array_time,element_array_index, vertices, velocities,node_array_mass, element_array_inverse_equilibrium_position)\n",
    "#     #     integrate_system_implicit_asynchronous(tf, element_array_time, element_array_stepsize, node_array_time,      element_array_index, vertices, velocities, node_array_mass, element_array_inverse_equilibrium_position, atol_x, atol_v, btol_x, btol_v, learning_rate)\n",
    "# #     integrate_system_dormand_prince_synchronous(tf,element_array_time,element_array_stepsize,node_array_time,element_array_index,vertices,velocities, node_array_mass,element_array_inverse_equilibrium_position,element_array_mass)\n",
    "# #     integrate_system_dormand_prince_asynchronous(tf,element_array_time,element_array_stepsize,node_array_time,element_array_index,vertices,velocities, node_array_mass,element_array_inverse_equilibrium_position,element_array_mass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T23:31:19.589252Z",
     "start_time": "2020-12-13T23:31:19.567249Z"
    }
   },
   "outputs": [],
   "source": [
    "#prepare for video\n",
    "###CAUTION WHEN RUNNING IN PARALLEL\n",
    "frameno = 1\n",
    "time_between_observations = 0.01\n",
    "time_of_next_observation = tme + time_between_observations\n",
    "os.chdir(nb_dir)\n",
    "os.chdir(folder_vid)\n",
    "with open(\"mov/text.txt\", \"w\") as file:\n",
    "    file.write(TEXT)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T23:31:19.667011Z",
     "start_time": "2020-12-13T23:31:19.591473Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(nb_dir)\n",
    "os.chdir(folder_vid)\n",
    "folnm = os.path.basename(save_folder_vid)\n",
    "shutil.rmtree(folnm)\n",
    "os.mkdir(folnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T23:31:19.688387Z",
     "start_time": "2020-12-13T23:31:19.668347Z"
    }
   },
   "outputs": [],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T23:31:15.368Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timothytyree/Documents/GitHub/avi/nb/lib/controller/integrate_forward_explicit_asynchronous.py:45: NumbaPerformanceWarning: '@' is faster on contiguous arrays, called on (array(float64, 2d, C), array(float64, 2d, A))\n",
      "  next_stepsize, retval, madval = step_forward_and_learn_simple(K_index, t_given, node_array_time, element_array_time, vertices, velocities, element_array_index,\n",
      "/Users/timothytyree/Documents/GitHub/avi/nb/lib/measure/mesh_measures.py:35: NumbaPerformanceWarning: '@' is faster on contiguous arrays, called on (array(float64, 2d, C), array(float64, 2d, A))\n",
      "  element_array_energy = comp_element_array_energy(N_elements, element_array_mass, velocities, vertices,\n"
     ]
    }
   ],
   "source": [
    "#ready... get set... GO!\n",
    "os.chdir(nb_dir)\n",
    "os.chdir(save_folder_vid)\n",
    "time_end_recording = 3#.2\n",
    "while time_of_next_observation <= time_end_recording:\n",
    "    tf = time_of_next_observation\n",
    "    #integrate forward to the next time of observation\n",
    "    #     integrate_system_explicit_synchronous(tf, element_array_time, element_array_stepsize, node_array_time,element_array_index, vertices, velocities,node_array_mass, element_array_inverse_equilibrium_position)\n",
    "    integrate_system_explicit_asynchronous(tf, element_array_time, element_array_stepsize, node_array_time,element_array_index, vertices, velocities, node_array_mass, element_array_inverse_equilibrium_position, atol_x, atol_v, btol_x, btol_v, learning_rate)\n",
    "    #     integrate_system_implicit_synchronous(tf, element_array_time, element_array_stepsize, node_array_time,element_array_index, vertices, velocities,node_array_mass, element_array_inverse_equilibrium_position)\n",
    "    #     integrate_system_implicit_asynchronous(tf, element_array_time, element_array_stepsize, node_array_time,      element_array_index, vertices, velocities, node_array_mass, element_array_inverse_equilibrium_position, atol_x, atol_v, btol_x, btol_v, learning_rate)\n",
    "    #     integrate_system_dormand_prince_synchronous(tf,element_array_time,element_array_stepsize,node_array_time,element_array_index,vertices,velocities, node_array_mass,element_array_inverse_equilibrium_position,element_array_mass)\n",
    "    #     integrate_system_dormand_prince_asynchronous(tf,element_array_time,element_array_stepsize,node_array_time,element_array_index,vertices,velocities, node_array_mass,element_array_inverse_equilibrium_position,element_array_mass)\n",
    "\n",
    "    #update a copy of all positions to the observation time using the current velocity\n",
    "    x = vertices.copy()\n",
    "    for a in range(N_vertices):\n",
    "        x[a] += velocities[a] * (tf - tau[a])\n",
    "    \n",
    "    #measure observables\n",
    "    ##mesh measures\n",
    "    net_volume = compute_net_volume(x, element_array_index)\n",
    "    net_energy = compute_net_energy(N_elements, element_array_mass, velocities, x, #vertices,\n",
    "                                  element_array_index, element_array_inverse_equilibrium_position, mu, lam)\n",
    "    ##stepsize measures\n",
    "    stepsize_mean = np.mean(element_array_stepsize)\n",
    "    stepsize_std = np.std(element_array_stepsize)\n",
    "    stepsize_median = np.median(element_array_stepsize)\n",
    "\n",
    "    #record observables\n",
    "    volume_lst.append(net_volume)\n",
    "    energy_lst.append(net_energy)\n",
    "    tme = tf\n",
    "    tme_lst.append(tme)\n",
    "    stepsize_mean_lst.append(stepsize_mean)\n",
    "    stepsize_std_lst.append(stepsize_std)\n",
    "    stepsize_median_lst.append(stepsize_median)\n",
    "    stepsize_count_lst.append(count_array(array = element_array_stepsize,bins=learning_bins))\n",
    "    #record image of system\n",
    "    try:\n",
    "        img = get_img_of_system(vertices, input_file_name, darkmode = False, text=f'time={tf:.2f}')\n",
    "    except:\n",
    "        pass\n",
    "    save_fn_img = f'img{frameno:09}.png'\n",
    "    frameno += 1\n",
    "    Img = Image.fromarray(img)\n",
    "    Img.save(save_fn_img)\n",
    "    del Img\n",
    "    #increment time_of_next_observation\n",
    "    time_of_next_observation += time_between_observations\n",
    "    #TODO(later): do something that makes a boring video less boring\n",
    "    #TODO(later): def element_array_count_calls_one_step to the call of integrate_system_.... i.e. Keep track of how many times each element is called to time step\n",
    "    #TODO(later): keep track of how many times each element config is updated with element_array_count_config_updates\n",
    "print(stepsize_mean, stepsize_std, stepsize_median)\n",
    "#TODO: include a progress bar...? No. put in a function!\n",
    "beep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T23:31:15.371Z"
    }
   },
   "outputs": [],
   "source": [
    "print(time_of_next_observation)\n",
    "from scipy.stats.mstats import gmean\n",
    "# print(np.hmean(element_array_stepsize), gmean(element_array_stepsize))\n",
    "print(gmean(element_array_stepsize))\n",
    "print(np.mean(element_array_stepsize))\n",
    "print(stepsize_init)\n",
    "tme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T23:31:15.374Z"
    }
   },
   "outputs": [],
   "source": [
    "fontsize=20\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.hist(element_array_stepsize, bins=100)\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "plt.ylabel('freq. of time step size',fontsize=fontsize)\n",
    "plt.xlabel('final time step size',fontsize=fontsize)\n",
    "\n",
    "# ax.set_title('Scores by group and gender')\n",
    "# plt.xticks(x)#,fontsize=fontsize)\n",
    "# plt.xticklabels(labels,fontsize=fontsize)\n",
    "# plt.legend(fontsize=fontsize-4)\n",
    "# plt.ylim([0,150])\n",
    "# ax.set_xlabel('time',**axkwargs)\n",
    "# ax.set_ylabel('variance in step size',**axkwargs)\n",
    "plt.tick_params(labelsize=fontsize, labelrotation=20)\n",
    "\n",
    "# ax.set_xlabel('time',**axkwargs)\n",
    "# ax.set_ylabel('volume / initial volume',**axkwargs)\n",
    "# plt.tick_params(labelsize=fontsize)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T23:31:15.376Z"
    }
   },
   "outputs": [],
   "source": [
    "# img = get_img_of_system(vertices, input_file_name, darkmode = True, text=f'time={tf:.2f}')\n",
    "# img\n",
    "stepsize_init\n",
    "# plt.tick_params?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T05:53:24.418106Z",
     "start_time": "2020-12-11T04:05:22.777Z"
    }
   },
   "source": [
    "__problem/bug confirmed__ integrate_system_dormand_prince_asynchronous is only decreasing the stepsize values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " __Verified that__ all variables are changed by the integrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__time is now being updated at the nodes__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save csv of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T23:31:15.392Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    't':tme_lst,\n",
    "    'volume':volume_lst,\n",
    "    'energy':energy_lst,\n",
    "    'stepsize_mean':stepsize_mean_lst,\n",
    "    'stepsize_std':stepsize_std_lst,\n",
    "    'stepsize_median':stepsize_median_lst,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T23:31:15.395Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T23:31:15.397Z"
    }
   },
   "outputs": [],
   "source": [
    "# x_values = df['t'].values\n",
    "# # y_values = df['volume'].values\n",
    "# y_values = df['energy'].values\n",
    "# plt.plot(x_values, y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T23:31:15.399Z"
    }
   },
   "outputs": [],
   "source": [
    "x_values = df['t'].values\n",
    "# y_values = df['volume'].values\n",
    "# y_values = df['energy'].values\n",
    "plt.plot(x_values, df['volume'].values/(4*np.pi*1.**3/3), label='volume/initial volume')\n",
    "plt.plot(x_values, df['energy'].values, label='energy')\n",
    "plt.legend()\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('measurement value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T18:26:26.431404Z",
     "start_time": "2020-12-10T18:26:26.388572Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T23:31:15.402Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_fn = f\"avi_ns_a_equal_b_{os.path.basename(input_file_name).replace('.stl',f'_mu_{mu}_lambda_{lam}_gamma_{gamma}vscale_{v_scale}_stepsizeinit_{stepsize_init}')}.csv\"\n",
    "\n",
    "os.chdir(data_folder)\n",
    "df.to_csv(data_fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T23:31:15.403Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'results saved as {data_fn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T23:31:15.405Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array(stepsize_count_lst)\n",
    "# np.savez(data_fn_counts)\n",
    "np.save(data_fn_counts, np.array(stepsize_count_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T06:07:29.968597Z",
     "start_time": "2020-12-10T06:07:29.899303Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T23:31:15.407Z"
    }
   },
   "outputs": [],
   "source": [
    "# set(stepsize_count_lst)\n",
    "np.array(stepsize_count_lst[0])\n",
    "np.array(stepsize_count_lst[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compile and save the movie using ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T23:31:15.411Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(nb_dir)\n",
    "os.chdir(os.path.dirname(save_folder_vid))\n",
    "vid_in_fn = 'out.mov'\n",
    "vid_out_fn = data_fn.replace('.csv','.mov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T23:31:15.414Z"
    }
   },
   "outputs": [],
   "source": [
    "!./concat_folder_png.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T23:31:15.415Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(nb_dir)\n",
    "os.chdir(os.path.dirname(save_folder_vid))\n",
    "assert(os.path.exists(vid_in_fn))\n",
    "destination = shutil.copyfile(vid_in_fn, vid_out_fn) \n",
    "beep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T23:31:15.417Z"
    }
   },
   "outputs": [],
   "source": [
    "os.path.exists(vid_out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T23:31:15.418Z"
    }
   },
   "outputs": [],
   "source": [
    "stepsize_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
